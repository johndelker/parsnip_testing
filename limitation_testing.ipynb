{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParSNIP Limitation Testing\n",
    "\n",
    "This notebook is for testing the limitations of ParSNIP by modifying datasets, making predictions and classifications, and comparing the results to those of unmodified data sets. Currently, it tests how the accuracy of ParSNIP degrades as the number of observations decreases.\n",
    "\n",
    "Written by John Delker (jfla@uw.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The update_default_config function is deprecated and may be removed in a future version. [sncosmo]\n"
     ]
    }
   ],
   "source": [
    "# Load dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.table import Table, vstack\n",
    "import time\n",
    "import parsnip\n",
    "import lcdata\n",
    "from ipywidgets import interact, interactive, interactive_output, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from collections import namedtuple\n",
    "from IPython.display import display\n",
    "import pandas\n",
    "\n",
    "# Hide a few warnings that would otherwise fill the page\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"'verbose' argument is deprecated and will be removed in a future release of LightGBM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "all_bands = [\"lsstu\", \"lsstg\", \"lsstr\", \"lssti\", \"lsstz\", \"lssty\"]\n",
    "band_colors = [\"blue\", \"green\", \"red\", \"purple\", \"brown\", \"black\"]\n",
    "model = parsnip.load_model(\"plasticc\") # Options: \"ps1\", \"plasticc\"\n",
    "Curve = namedtuple('Curve', 'time flux results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'plasticc_test_slim.h5' as PLAsTiCC dataset...\n",
      "Rejecting 0 non-supernova-like light curves.\n",
      "Dataset contains 5000 light curves.\n"
     ]
    }
   ],
   "source": [
    "# Prepares the dataset, removing any objects whose type ParSNIP can not explicitly classify\n",
    "plasticc_dataset = parsnip.load_dataset(\"../data/plasticc_test_slim.h5\")\n",
    "plasticc_dataset = plasticc_dataset[~(plasticc_dataset.meta['type'] == 'CaRT')]\n",
    "plasticc_dataset = plasticc_dataset[~(plasticc_dataset.meta['type'] == 'ILOT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier with keys:\n",
      "    color\n",
      "    color_error\n",
      "    s1\n",
      "    s1_error\n",
      "    s2\n",
      "    s2_error\n",
      "    s3\n",
      "    s3_error\n",
      "    luminosity\n",
      "    luminosity_error\n",
      "    reference_time_error\n",
      "[100]\tvalid_0's multi_logloss: 0.495647\n",
      "[100]\tvalid_0's multi_logloss: 0.509514\n",
      "[100]\tvalid_0's multi_logloss: 0.536781\n",
      "[100]\tvalid_0's multi_logloss: 0.531477\n",
      "[100]\tvalid_0's multi_logloss: 0.469776\n",
      "[100]\tvalid_0's multi_logloss: 0.518461\n",
      "[100]\tvalid_0's multi_logloss: 0.532923\n",
      "[100]\tvalid_0's multi_logloss: 0.488277\n",
      "[100]\tvalid_0's multi_logloss: 0.491106\n",
      "[100]\tvalid_0's multi_logloss: 0.549328\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "classifier = parsnip.Classifier()\n",
    "training_predictions = Table.read('../predictions/parsnip_predictions_plasticc_train_aug_100.h5')\n",
    "training_classifications = classifier.train(training_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_bands(dataset, bands):\n",
    "    '''For each sample in the dataset, removes all points that are not part of the given bands'''\n",
    "    \n",
    "    # Makes a copy of the dataset so that the original is left unmodified\n",
    "    modified_dataset = lcdata.Dataset(dataset.meta.copy(), dataset.light_curves.copy())\n",
    "    \n",
    "    # Group the light curves by band\n",
    "    for i in range(0, len(modified_dataset)):\n",
    "        light_curve = dataset.light_curves[i].group_by('band')\n",
    "        group_count = len(light_curve.groups.indices) - 1\n",
    "\n",
    "        # Mask out all points that are part of any band that is being removed for this test\n",
    "        mask = np.ones(len(light_curve), dtype=bool)\n",
    "        for n in range(0, group_count):\n",
    "            if light_curve.groups.keys[\"band\"][n] in bands: continue\n",
    "            mask[light_curve.groups.indices[n] : light_curve.groups.indices[n + 1]] = False\n",
    "            \n",
    "        # Apply the mask and return to the original sorting method to prevent possible issues\n",
    "        modified_dataset.light_curves[i] = light_curve[mask]\n",
    "        modified_dataset.light_curves[i].sort(\"time\")\n",
    "    \n",
    "    return modified_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_observation_count(dataset, max_observations_per_band):\n",
    "    '''Removes observations past the max number of observations specified.'''\n",
    "    \n",
    "    # Makes a copy of the dataset so that the original is left unmodified\n",
    "    modified_dataset = lcdata.Dataset(dataset.meta.copy(), dataset.light_curves.copy())\n",
    "    \n",
    "    # For each object in the dataset, limit the number of observations in each band\n",
    "    for i in range(0, len(modified_dataset)):\n",
    "\n",
    "        # Group the light curves by band so that each band can be manipulated individually\n",
    "        light_curve = dataset.light_curves[i].group_by('band')\n",
    "        group_count = len(light_curve.groups.indices) - 1\n",
    "\n",
    "        # Create a mask to remove points from each group/band\n",
    "        mask = np.ones(len(light_curve), dtype=bool)\n",
    "        for n in range(0, group_count):\n",
    "            lower_bound = light_curve.groups.indices[n]\n",
    "            upper_bound = light_curve.groups.indices[n + 1]\n",
    "\n",
    "            # Otherwise, only mask out the portion that would be above the point cutoff\n",
    "            # Note: A cutoff of \"None\" retains all original observations\n",
    "            if max_observations_per_band is not None and lower_bound + max_observations_per_band < upper_bound:\n",
    "                mask[lower_bound + max_observations_per_band : upper_bound] = False\n",
    "\n",
    "        # Apply the mask and return to the original sorting method to prevent possible issues\n",
    "        modified_dataset.light_curves[i] = light_curve[mask]\n",
    "        modified_dataset.light_curves[i].sort(\"time\")\n",
    "    \n",
    "    return modified_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limitation_test(sample_size, bands, observation_cutoffs = [], object_index = None):\n",
    "    '''\n",
    "    Takes a sample of the given dataset and returns the predictions and classifications for each sample\n",
    "    along with predictions and classifications made using degraded versions of those sample.\n",
    "    '''\n",
    "    \n",
    "    global model, plasticc_dataset\n",
    "    \n",
    "    # If only looking at one object, grab that part of the dataset; otherwise, grab the first X objects\n",
    "    if not(object_index is None): dataset = plasticc_dataset[object_index]\n",
    "    else: dataset = plasticc_dataset[0:sample_size]\n",
    "        \n",
    "    # Remove unused bands from the dataset\n",
    "    dataset = restrict_bands(dataset, bands)\n",
    "    \n",
    "    # Classify the dataset with points removed for each cutoff given, and once without points removed as a control\n",
    "    observation_cutoffs.insert(0, None)\n",
    "    classified_data = { \"used_bands\": bands, \"used_cutoffs\": observation_cutoffs }\n",
    "    for cutoff in observation_cutoffs:\n",
    "    \n",
    "        # Modifies the dataset with a cutoff for observations, then generates predictions and classifications\n",
    "        modified_dataset = restrict_observation_count(dataset, cutoff)\n",
    "        predictions = model.predict_dataset(modified_dataset)\n",
    "        classifications = classifier.classify(predictions)\n",
    "\n",
    "        # For every object in the dataset, store the classification and relevant info\n",
    "        for index in range(0, len(predictions)):\n",
    "            \n",
    "            # Stores on a per-object basis to easily compare how an individual object is affected by modifications\n",
    "            object_id = classifications[\"object_id\"][index]\n",
    "            object_info = classified_data.get(object_id)\n",
    "            if object_info is None: object_info = []\n",
    "            \n",
    "            # Find the classification considered most likely by the classifier\n",
    "            top_prediction = None\n",
    "            for c in classifications.colnames:\n",
    "                if c == \"object_id\": continue\n",
    "                if top_prediction == None or classifications[c][index] > classifications[top_prediction][index]:\n",
    "                    top_prediction = c\n",
    "            \n",
    "            # Uses ParSNIP to predict the full light curve based on modified samples\n",
    "            predicted_curve = model.predict_light_curve(modified_dataset.light_curves[index], False)\n",
    "            \n",
    "            # Collects all the most important info from dataset, predictions, and classifications into one place\n",
    "            object_info.append({\n",
    "                \"cutoff\": cutoff, \n",
    "                \"truth\": modified_dataset.meta['type'][index],\n",
    "                \"prediction\": top_prediction,\n",
    "                \"light_curve\": modified_dataset.light_curves[index], \n",
    "                \"predicted_curve\": Curve(predicted_curve[0], predicted_curve[1], predicted_curve[2]),\n",
    "                \"SNIa\": classifications[\"SNIa\"][index], \n",
    "                \"SNII\": classifications[\"SNII\"][index], \n",
    "                \"SLSN-I\": classifications[\"SLSN-I\"][index], \n",
    "                \"SNIa-91bg\": classifications[\"SNIa-91bg\"][index], \n",
    "                \"SNIax\": classifications[\"SNIax\"][index], \n",
    "                \"SNIbc\": classifications[\"SNIbc\"][index], \n",
    "                \"TDE\": classifications[\"TDE\"][index], \n",
    "                \"KN\": classifications[\"KN\"][index]\n",
    "            })\n",
    "            \n",
    "            classified_data.update({ object_id: object_info })\n",
    "        \n",
    "    return classified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(dataset, cutoffs, object_index, cutoff, used_bands, shown_bands, show_scatter):\n",
    "    '''\n",
    "    Predicts the light curves for an object, for each modification made to that object, and plots\n",
    "    those light curves with scatter, error bars, and the unmodified light curve for comparison.\n",
    "    '''\n",
    "    \n",
    "    global model\n",
    "    \n",
    "    if \"ALL\" in used_bands: used_bands = all_bands\n",
    "    if \"ALL\" in shown_bands: shown_bands = all_bands\n",
    "        \n",
    "    cutoff_value = cutoffs[cutoff - 1] if cutoff > 0 else None\n",
    "    used_cutoffs = [cutoff_value] if cutoff > 0 else []\n",
    "    cutoff_index = 1 if cutoff > 0 else 0\n",
    "        \n",
    "    # Make classifications for the given settings\n",
    "    data = limitation_test(1, used_bands, used_cutoffs, object_index)\n",
    "    object_id = list(data.keys())[2]\n",
    "    true_class = data[object_id][0]['truth']\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (12, 5))\n",
    "        \n",
    "    primary_light_curve = data[object_id][0][\"light_curve\"]\n",
    "    primary_predicted_curve = data[object_id][0][\"predicted_curve\"]\n",
    "    start_time = np.min(primary_predicted_curve.time)\n",
    "    \n",
    "    # Determining the vertical axis limits to show as much as possible without losing any data\n",
    "    if show_scatter != \"off\": min_y = min(primary_light_curve[\"flux\"])\n",
    "    else: min_y = min(primary_predicted_curve.flux.flatten())\n",
    "    max_y = max(primary_predicted_curve.flux.flatten())\n",
    "    \n",
    "    for band in shown_bands:\n",
    "        if not(band in used_bands): continue\n",
    "        band_index = all_bands.index(band)\n",
    "        \n",
    "        # Plots the predicted light curve for the unmodified sample in the given band\n",
    "        ax.plot((primary_predicted_curve.time - np.min(start_time)), primary_predicted_curve.flux[0][band_index], \n",
    "                            label = f\"{len(primary_light_curve)} points (original)\", \n",
    "                            linestyle = \"--\", linewidth = 1, color = band_colors[band_index])\n",
    "        \n",
    "        light_curve = data[object_id][cutoff_index][\"light_curve\"]\n",
    "        light_curve_mask = light_curve[\"band\"] == band\n",
    "\n",
    "        # Plot the individual observations and their flux error in the given band\n",
    "        if show_scatter != \"off\":\n",
    "            error = light_curve[light_curve_mask]['fluxerr'] if show_scatter == \"with error\" else np.zeros(len(light_curve[light_curve_mask]['fluxerr']))\n",
    "            ax.errorbar(light_curve[light_curve_mask]['time'] - start_time, light_curve[light_curve_mask]['flux'], \n",
    "                                    yerr = error, fmt = '.', label = band, color = band_colors[band_index])\n",
    "\n",
    "        if cutoff_value != None:\n",
    "            predicted_curve = data[object_id][cutoff_index][\"predicted_curve\"]\n",
    "            ax.plot(predicted_curve.time - start_time, predicted_curve.flux[0][band_index], \n",
    "                                label = f\"{len(light_curve)} points\", linewidth = 1.5, \n",
    "                                color = band_colors[band_index])\n",
    "\n",
    "            max_y = max(max(predicted_curve.flux.flatten()), max_y)\n",
    "        \n",
    "    ax.set_ylim(top = max_y + 2, bottom = min_y - 2)\n",
    "\n",
    "    # What is the predicted class and it's associated probability?\n",
    "    predicted_class = data[object_id][cutoff_index]['prediction']\n",
    "    prediction_probability = data[object_id][cutoff_index][predicted_class]\n",
    "    title = f\"{(prediction_probability * 100):.2f}% {predicted_class}\"\n",
    "\n",
    "    # If the predicted class is incorrect, what is the predicted probability of the true class?\n",
    "    if predicted_class != true_class: \n",
    "        truth_probability = data[object_id][cutoff_index][true_class]\n",
    "        title = f\"{title} ({(truth_probability * 100):.2f}% {true_class})\"\n",
    "\n",
    "    # Make predicted and true class probabilities the title of each plot\n",
    "    ax.set_title(title)\n",
    "    fig.suptitle(object_id)\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactable_curve(dataset, cutoffs):\n",
    "    ''' Creates an interactable plot that compares predicted light curves. '''\n",
    "    \n",
    "    object_index = widgets.BoundedIntText(min = 0, max = len(plasticc_dataset) - 1, step = 1, value = 0, description = \"Object Index:\", continuous_update = False)\n",
    "    cutoff = widgets.IntSlider(min = 0, max = len(cutoffs), step = 1, value = 0, description = \"Cutoff:\", continuous_update = False)\n",
    "    used_bands = widgets.SelectMultiple(options = [\"ALL\"] + all_bands, rows = 3, value = [\"ALL\"], description = \"Use Bands:\")\n",
    "    shown_bands = widgets.SelectMultiple(options = [\"ALL\"] + all_bands, rows = 3, value = [\"ALL\"], description = \"See Bands:\")\n",
    "    show_scatter = widgets.RadioButtons(options = ['with error', 'no error', 'off'], description = \"Scatter:\")\n",
    "\n",
    "    ui = widgets.HBox([\n",
    "        widgets.VBox([object_index, cutoff, show_scatter]), \n",
    "        widgets.VBox([used_bands, shown_bands])\n",
    "    ])\n",
    "    \n",
    "    output = widgets.interactive_output(plot_curve, {\"dataset\": fixed(dataset), \"cutoffs\": fixed(cutoffs), \"object_index\": object_index,\n",
    "         \"cutoff\": cutoff, \"used_bands\": used_bands, \"shown_bands\": shown_bands, \"show_scatter\": show_scatter});\n",
    "    \n",
    "    display(output, ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Just a quick way to check on the probabilities assigned to each classification for each object for each cutoff\n",
    "def print_classifications(data):\n",
    "    for object_id in data:\n",
    "        if object_id == \"used_bands\" or object_id == \"used_cutoffs\": continue\n",
    "        print(\"==============================\")\n",
    "        print(f\"OBJECT {object_id}, TRUTH - {data[object_id][0]['truth']}\")\n",
    "        print(\"==============================\")\n",
    "        for index in range(0, len(data[object_id])):\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"{len(data[object_id][index]['light_curve'])} POINTS USED\")\n",
    "            print(\"------------------------------\")\n",
    "            for key in data[object_id][index]:\n",
    "                if key != \"cutoff\" and key != \"light_curve\" and key != \"truth\" and key != \"predicted_curve\": \n",
    "                    text = f\"{key}: {data[object_id][index][key]}\"\n",
    "                    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(data):\n",
    "    \n",
    "    table = pandas.DataFrame({\n",
    "        \"SNIa\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"SNII\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"SLSN-I\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"SNIa-91bg\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"SNIax\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"SNIbc\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        \"TDE\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 },\n",
    "        #\"KN\": { \"SNIa\" : 0., \"SNII\": 0, \"SLSN-I\": 0, \"SNIa-91bg\": 0, \"SNIax\": 0, \"SNIbc\": 0, \"TDE\": 0., \"KN\": 0., \"Count\": 0 }\n",
    "    })\n",
    "    \n",
    "    for object_id in data:\n",
    "        if object_id == \"used_bands\" or object_id == \"used_cutoffs\": continue\n",
    "        truth = data[object_id][0]['truth']\n",
    "        table.loc[\"Count\", truth] += 1\n",
    "        for index in range(0, len(data[object_id])):\n",
    "            for key in data[object_id][index]:\n",
    "                if not(key in [\"cutoff\", \"light_curve\", \"truth\", \"prediction\", \"predicted_curve\"]): \n",
    "                    table.loc[key, truth] += data[object_id][index][key]\n",
    "                    \n",
    "    for col in table:\n",
    "        for index, row in table.iterrows():\n",
    "            if index == \"Count\": continue\n",
    "            table.loc[index, col] = (table.loc[index, col] * 100) / table.loc[\"Count\", col]\n",
    "        \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40139e11f7424682a1cfc097ea4341a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b5d0cc3e064585b8ad01f0d78cc482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(BoundedIntText(value=0, description='Object Index:', max=4965), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_interactable_curve(plasticc_dataset, [32, 16, 8, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a plot where x axis is the point cutoff, y axis is the classifications and it is chopped into grids. \n",
    "#       Each block should either have a value or be colored based on how likely that classification is for that cutoff\n",
    "#       And possibly plot a stacked version for every sample combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset: 100%|██████████| 4500/4500 [00:09<00:00, 470.37it/s]\n",
      "Preprocessing dataset: 100%|██████████| 4500/4500 [00:09<00:00, 464.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_classifications = limitation_test(4500, all_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  SNIa         SNII      SLSN-I   SNIa-91bg       SNIax  \\\n",
      "SNIa         74.679164     3.933075    3.973046    4.205411   39.078961   \n",
      "SNII         58.019996    84.997457   63.359513   12.529328   64.781812   \n",
      "SLSN-I        2.788474     2.050992  117.420966    5.798780    0.521484   \n",
      "SNIa-91bg    11.660122     2.838719    3.031256  156.895947   24.163603   \n",
      "SNIax        14.822545    10.745085    0.663644    6.083171   30.023262   \n",
      "SNIbc         7.220638    17.906438    9.542829   11.439454   28.599268   \n",
      "TDE          30.244321    75.695777    1.785350    0.506685    8.875490   \n",
      "KN            0.564740     1.832456    0.223396    2.541223    3.956120   \n",
      "Count      1777.000000  2226.000000   10.000000   48.000000  121.000000   \n",
      "\n",
      "                SNIbc         TDE  \n",
      "SNIa         6.435669    0.832774  \n",
      "SNII        53.488944    4.709081  \n",
      "SLSN-I       0.710271    0.686649  \n",
      "SNIa-91bg   40.673284    0.461986  \n",
      "SNIax       14.113908    0.894841  \n",
      "SNIbc       72.840507    3.217292  \n",
      "TDE          4.287504   85.199235  \n",
      "KN           7.449913  103.998141  \n",
      "Count      311.000000    7.000000  \n"
     ]
    }
   ],
   "source": [
    "print_accuracy(test_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "John Delker's Python 3.10",
   "language": "python",
   "name": "jfla_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
